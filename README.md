#  Previs√£o de Congestionamentos em S√£o Paulo com Machine Learning

[![Python](https://img.shields.io/badge/Python-3.13.7-blue.svg)](https://www.python.org/)
[![Status](https://img.shields.io/badge/Status-Research%20Project-orange)]()
[![Made with](https://img.shields.io/badge/Made%20with-üí°%20Machine%20Learning-brightgreen)]()

---

Este reposit√≥rio apresenta uma **pesquisa aplicada** que utiliza **t√©cnicas de aprendizado de m√°quina (Machine Learning)** para prever o **tamanho de congestionamentos** em **S√£o Paulo**, com base em dados hist√≥ricos de **tr√°fego urbano** e **popula√ß√£o regional**.

O estudo busca entender como vari√°veis sociais e temporais influenciam o comportamento do tr√¢nsito em grandes centros urbanos.

---

## Estrutura do Projeto

```
pesquisa_aplicada/
‚îÇ
‚îú‚îÄ‚îÄ rawData/                  # Dados brutos de entrada (popula√ß√£o, tr√¢nsito)
‚îú‚îÄ‚îÄ clean/                    # Dados limpos e tratados
‚îÇ
‚îú‚îÄ‚îÄ clear_population.py       # Limpeza e normaliza√ß√£o dos dados populacionais
‚îú‚îÄ‚îÄ clear_traffic.py          # Limpeza e normaliza√ß√£o dos dados de congestionamentos
‚îÇ
‚îú‚îÄ‚îÄ preparedData/             # Dataset unificado pronto para modelagem
‚îÇ
‚îú‚îÄ‚îÄ results/                  # Resultados e gr√°ficos dos experimentos
‚îÇ   ‚îú‚îÄ‚îÄ resultados_knn_*.json
‚îÇ   ‚îú‚îÄ‚îÄ resultados_rf_*.json
‚îÇ   ‚îú‚îÄ‚îÄ resultados_xgboost_*.json
‚îÇ   ‚îú‚îÄ‚îÄ resultados_mlp_*.json
‚îÇ   ‚îî‚îÄ‚îÄ resultados_linear_*.json
‚îÇ
‚îî‚îÄ‚îÄ estrutura_projeto.md      # Estrutura metodol√≥gica do artigo cient√≠fico
```

---

## Objetivo

Explorar modelos de regress√£o supervisionada para prever o **tamanho do congestionamento (em metros)** com base em vari√°veis como:

* Regi√£o da cidade
* Hor√°rio e dia da semana
* M√™s do ano
* Via expressa
* Popula√ß√£o total por sexo

---

## Pipeline Metodol√≥gico

### 1. **Aquisi√ß√£o e Integra√ß√£o de Dados**

Dados coletados de fontes p√∫blicas.
Durante o merge, a granularidade populacional foi simplificada para **total de homens e mulheres por regi√£o/ano**, reduzindo o dataset de **170 GB** para uma vers√£o vi√°vel (~300k registros).

### 2. **Limpeza e Padroniza√ß√£o**

Scripts automatizados realizam o tratamento:

* `clear_population.py` ‚Üí limpa e mapeia distritos por regi√£o, remove acentos, filtra idades ‚â• 20 anos e gera relat√≥rio.
* `clear_traffic.py` ‚Üí valida datas e hor√°rios, normaliza textos, remove duplicatas e exporta dados limpos.

### 3. **Modelagem Preditiva**

Foram comparados cinco modelos:

| Modelo                | R¬≤ (Teste) | MAE (Teste) | Observa√ß√µes                        |
| --------------------- | ---------- | ----------- | ---------------------------------- |
| **KNN**               | 0.53       | 786.20      | Sens√≠vel √† escala das features     |
| **Random Forest**     | **0.62**   | 760.17      | Melhor desempenho geral            |
| **XGBoost**           | 0.51       | 953.15      | Est√°vel, leve overfitting          |
| **MLP Neural Net**    | 0.47       | 988.53      | Potencial para otimiza√ß√£o          |
| **Linear Regression** | 0.10       | 1379.68     | Baixo ajuste para n√£o linearidades |

> As an√°lises incluem **gr√°ficos SHAP**, **curvas de erro** e **import√¢ncia das features** para interpreta√ß√£o dos resultados.

### 4. **Avalia√ß√£o**

Foram usadas m√©tricas de erro e explicabilidade:

* **MAE, RMSE, R¬≤**
* **Feature Importance / Coeficientes**
* **An√°lise SHAP**

A vari√°vel **pop_total** foi a mais influente, seguida de **via_expressa_encoded** e **m√™s**, mostrando que o comportamento do tr√¢nsito √© fortemente impactado por fatores demogr√°ficos e sazonais.

---

## Instala√ß√£o e Execu√ß√£o

### 1. Clonar o Reposit√≥rio

```bash
git clone https://github.com/Alexandre-Tortoza/pesquisa_aplicada.git
cd pesquisa_aplicada
```

### 2. Criar e Ativar Ambiente Virtual

```bash
python -m venv .venv
source .venv/bin/activate  # Linux / Mac
.venv\Scripts\activate     # Windows
```

### 3. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

*(Se o arquivo `requirements.txt` ainda n√£o existe, pode ser criado com:)*

```bash
pip freeze > requirements.txt
```

### 4. Executar os Pipelines de Limpeza

```bash
python clear_population.py
python clear_traffic.py
```

### 5. Treinar e Avaliar Modelos

Os notebooks ou scripts de modelagem est√£o na pasta `results/` e podem ser executados em sequ√™ncia para reproduzir os experimentos.

---

## Resultados Principais

* **Random Forest** obteve o melhor equil√≠brio entre precis√£o e interpretabilidade.
* **XGBoost** confirmou estabilidade com bom ajuste geral.
* **MLP** apresentou potencial para capturar rela√ß√µes n√£o lineares.
* A limpeza e unifica√ß√£o dos dados foram decisivas para a qualidade dos resultados.

---

## Tecnologias Utilizadas

| Categoria            | Ferramentas               |
| -------------------- | ------------------------- |
| Linguagem            | Python 3.13.7             |
| Manipula√ß√£o de Dados | Pandas, NumPy             |
| Modelagem            | Scikit-learn, XGBoost     |
| Visualiza√ß√£o         | Matplotlib, Seaborn, SHAP |
| Ambiente             | Neovim (Arch Linux) üêß    |

---

## Estrutura Cient√≠fica

Baseada no documento [`estrutura_projeto.md`](./estrutura_projeto.md), seguindo o formato cl√°ssico de artigos cient√≠ficos:

1. **Introdu√ß√£o** ‚Äì contextualiza√ß√£o e motiva√ß√£o.
2. **Metodologia** ‚Äì pipeline de dados e algoritmos.
3. **Resultados** ‚Äì compara√ß√µes quantitativas e visuais.
4. **Discuss√£o** ‚Äì implica√ß√µes e limita√ß√µes.
5. **Conclus√£o** ‚Äì s√≠ntese e contribui√ß√µes.

---


## Autor

**Alexandre Marques Tortoza Canoa**
[alexandre.tortoza@gmail.com](mailto:alexandre.tortoza@gmail.com)
[GitHub: Alexandre-Tortoza](https://github.com/Alexandre-Tortoza)
[alexandre-Tortoza.tech](https://alexandre-Tortoza.tech)
